{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Fai artificial inflation di alcune classi nel training set con un fattore di 10 (pesa di più le classi virginica e versicolor che sono più difficili da discriminare). Impara l'albero in queste condizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=300, min_samples_leaf=5, class_weight={0:1,1:1,2:1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing (artificial inflation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_with_target = np.c_[iris.data, iris.target]\n",
    "\n",
    "iris_data_with_target_0 = iris_data_with_target[iris_data_with_target[:,-1]==0]\n",
    "iris_data_with_target_1 = iris_data_with_target[iris_data_with_target[:,-1]==1]\n",
    "iris_data_with_target_2 = iris_data_with_target[iris_data_with_target[:,-1]==2]\n",
    "\n",
    "#iris_data_with_target_1 = np.repeat(iris_data_with_target_1, 10, axis=0)\n",
    "iris_data_with_target_2 = np.repeat(iris_data_with_target_2, 10, axis=0)\n",
    "\n",
    "#unsisci i tre array\n",
    "iris_data_with_target = np.concatenate((iris_data_with_target_0, iris_data_with_target_1, iris_data_with_target_2), axis=0)\n",
    "\n",
    "#separa le features dalle classi\n",
    "iris_data = iris_data_with_target[:,:-1]\n",
    "iris_target = iris_data_with_target[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_data))\n",
    "\n",
    "# We now decide to keep the last 10 indices for test set, the remaining for the training set\n",
    "indices_training = indices[:-60]\n",
    "indices_test = indices[-60:]\n",
    "\n",
    "iris_X_train = iris_data[indices_training] # keep for training all the matrix elements with the exception of the last 10 \n",
    "iris_y_train = iris_target[indices_training]\n",
    "iris_X_test  = iris_data[indices_test] # keep the last 10 elements for test set\n",
    "iris_y_test  = iris_target[indices_test]\n",
    "# fit the model to the training data\n",
    "clf = clf.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2.]\n",
      "True classes:\n",
      "[2. 2. 2. 2. 0. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 0. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 1. 2. 0. 2. 2. 2.]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# apply fitted model \"clf\" to the test set \n",
    "predicted_y_test = clf.predict(iris_X_test)\n",
    "\n",
    "# print the predictions (class numbers associated to classes names in target names)\n",
    "print(\"Predictions:\")\n",
    "print(predicted_y_test)\n",
    "print(\"True classes:\")\n",
    "print(iris_y_test) \n",
    "print(iris.target_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.95\n",
      "F1 score: 0.9230240549828178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "acc_score = accuracy_score(iris_y_test, predicted_y_test)\n",
    "print(\"Accuracy score: \"+ str(acc_score))\n",
    "f1=f1_score(iris_y_test, predicted_y_test, average='macro')\n",
    "print(\"F1 score: \"+str(f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90833333 0.91666667 0.96666667 0.90833333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris_data, iris_target, cv=5)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
